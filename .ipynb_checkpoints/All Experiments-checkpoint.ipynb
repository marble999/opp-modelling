{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ************************** Initing args for:  DEEPCOPY_v0   **************************\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bayesian PsuedoCount updating\n",
    "\"\"\"\n",
    "\n",
    "from RangeAgent import EvalAgentDeepRange\n",
    "from TreeAgent import EvalAgentTree\n",
    "from ucb import MAB\n",
    "\n",
    "from PokerRL.game.games import StandardLeduc  # or any other game\n",
    "from PokerRL.eval.rl_br.RLBRArgs import RLBRArgs\n",
    "\n",
    "from DeepCFR.EvalAgentDeepCFR import EvalAgentDeepCFR\n",
    "from DeepCFR.TrainingProfile import TrainingProfile\n",
    "from DeepCFR.workers.driver.Driver import Driver\n",
    "\n",
    "rlbr_args = RLBRArgs(\n",
    "    rlbr_bet_set = None\n",
    ")\n",
    "\n",
    "t_prof = TrainingProfile(\n",
    "    name=\"DEEPCOPY_v0\",\n",
    "    nn_type=\"feedforward\",\n",
    "    \n",
    "    max_buffer_size_adv=3e6,\n",
    "    eval_agent_export_freq=20,  # export API to play against the agent\n",
    "    n_traversals_per_iter=1500,\n",
    "    n_batches_adv_training=750,\n",
    "    n_batches_avrg_training=2000,\n",
    "    n_merge_and_table_layer_units_adv=64,\n",
    "    n_merge_and_table_layer_units_avrg=64,\n",
    "    n_units_final_adv=64,\n",
    "    n_units_final_avrg=64,\n",
    "    mini_batch_size_adv=2048,\n",
    "    mini_batch_size_avrg=2048,\n",
    "    init_adv_model=\"last\",\n",
    "    init_avrg_model=\"last\",\n",
    "    use_pre_layers_adv=False,\n",
    "    use_pre_layers_avrg=False,\n",
    "\n",
    "    game_cls=StandardLeduc,\n",
    "\n",
    "    # You can specify one or both modes. Choosing both is useful to compare them.\n",
    "    eval_modes_of_algo=(\n",
    "     # EvalAgentDeepCFR.EVAL_MODE_SINGLE,  # SD-CFR\n",
    "     EvalAgentDeepCFR.EVAL_MODE_AVRG_NET,  # Deep-CFR\n",
    "    ),\n",
    "\n",
    "    DISTRIBUTED=False,\n",
    "    rl_br_args=rlbr_args\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "action_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def hole_card_onehot(hole_card):\n",
    "    rank = hole_card[0][0]\n",
    "    suit = hole_card[0][1]\n",
    "    out = rank + suit * 3 ## arbitrary but it will learn the relationship\n",
    "    return torch.LongTensor([out])\n",
    "\n",
    "def best_response(agent):\n",
    "    \"\"\"\n",
    "    Returns strategy that is best response to agent strategy\n",
    "    \"\"\"\n",
    "    br = EvalAgentTree(t_prof, br_agent=agent, mode=None, device=None)\n",
    "    br.mode = \"BR\"\n",
    "    return br\n",
    "\n",
    "def train_while_play(student_agent, enemy_agent, args={'lr':1e-2, 'iters':10000}):\n",
    "    \"\"\"\n",
    "    Train student_agent to play against stationery enemy_agent.\n",
    "    \"\"\"\n",
    "            \n",
    "    env_bldr = student_agent.env_bldr\n",
    "    env_cls = env_bldr.env_cls\n",
    "    env_args = env_bldr.env_args\n",
    "    lut_holder = env_cls.get_lut_holder()\n",
    "    \n",
    "    assert(student_agent.env_bldr.env_cls == enemy_agent.env_bldr.env_cls)\n",
    "    assert(env_args.n_seats == 2)\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(student_agent.policy[0]._net.parameters()) + \\\n",
    "                                 list(student_agent.policy[1]._net.parameters()), lr=args['lr'])\n",
    "    start_time = time.time()\n",
    "    \n",
    "    REFERENCE_AGENT = 0\n",
    "    \n",
    "    _env = env_cls(env_args=env_args, lut_holder=lut_holder, is_evaluating=True)\n",
    "    _eval_agents = [enemy_agent, deepcopy(student_agent)] # play against an new frozen copy of the BR to agent while training\n",
    "    \n",
    "    results = {\n",
    "        \"action_loss\": [],\n",
    "        \"winnings\": []\n",
    "    }\n",
    "    iters = 0 # number of hands played\n",
    "    evals = 0 # number of teaching moments\n",
    "    \n",
    "    # zero grads, set net to train mode\n",
    "    student_agent.policy[0]._net.train()\n",
    "    student_agent.policy[1]._net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    while iters < args['iters']:\n",
    "        iters += 1\n",
    "        \n",
    "        if iters % 100 == 0:\n",
    "            print(\"Iters {} | Evals {} | ActionLoss {} | Winnings mBB/Hand {} | \".format(\n",
    "                iters, evals, sum(results['action_loss']) / evals, sum(results[\"winnings\"]) / iters\n",
    "            ))\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            ## _eval_agents[0] = deepcopy(student_agent)\n",
    "            \n",
    "            # play against an new frozen copy of the BR to agent while training\n",
    "            _eval_agents[1] = best_response(deepcopy(student_agent)) \n",
    "        \n",
    "        for seat_p0 in range(_env.N_SEATS):\n",
    "            seat_p1 = 1 - seat_p0\n",
    "            \n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            # Reset Episode\n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            _, r_for_all, done, info = _env.reset()\n",
    "            for e in _eval_agents:\n",
    "                e.reset(deck_state_dict=_env.cards_state_dict())\n",
    "\n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            # Play Episode\n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "            while not done:\n",
    "                p_id_acting = _env.current_player.seat_id\n",
    "\n",
    "                if p_id_acting == seat_p0:\n",
    "                    evals += 1 #increment counter\n",
    "                    \n",
    "                    # set student to position of agent 1, estimate range + actions\n",
    "                    student_agent.set_env_wrapper(_eval_agents[REFERENCE_AGENT]._internal_env_wrapper) \n",
    "                    student_a_probs = student_agent.get_a_probs_tensor()\n",
    "                    \n",
    "                    # get true values \n",
    "                    action_int, _ = _eval_agents[REFERENCE_AGENT].get_action(step_env=True, need_probs=False)\n",
    "                    \n",
    "                    # print(\"True:\", a_probs, range_label)\n",
    "                    # print(\"Prediction:\", student_a_probs, student_range_probs)\n",
    "                    # print(\"Checking requires_grad:\", student_a_probs.requires_grad, student_range_probs.requires_grad)\n",
    "                    \n",
    "                    # compute loss\n",
    "                    loss = action_loss(student_a_probs.view(1,-1), torch.LongTensor([action_int]))\n",
    "                    results['action_loss'].append(loss)\n",
    "                    \n",
    "                    # print(\"Loss:\", rloss, aloss, loss)\n",
    "                    \n",
    "                    # backpropogate\n",
    "                    loss.backward() # accumulate gradients over many steps\n",
    "                                        \n",
    "                    # notify opponent\n",
    "                    _eval_agents[1 - REFERENCE_AGENT].notify_of_action(p_id_acted=p_id_acting,\n",
    "                                                                       action_he_did=action_int)\n",
    "                elif p_id_acting == seat_p1:\n",
    "                    action_int, _ = _eval_agents[1 - REFERENCE_AGENT].get_action(step_env=True,\n",
    "                                                                                 need_probs=False)\n",
    "                    _eval_agents[REFERENCE_AGENT].notify_of_action(p_id_acted=p_id_acting,\n",
    "                                                                   action_he_did=action_int)\n",
    "                else:\n",
    "                    raise ValueError(\"Only HU supported!\")\n",
    "\n",
    "                _, r_for_all, done, info = _env.step(action_int)\n",
    "                \n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            # Add Rews\n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            results[\"winnings\"].append(r_for_all[seat_p0] * _env.REWARD_SCALAR * _env.EV_NORMALIZER)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Time taken\", end_time - start_time)\n",
    "\n",
    "    print(optimizer)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "action_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def best_response(agent):\n",
    "    \"\"\"\n",
    "    Returns strategy that is best response to agent strategy\n",
    "    \"\"\"\n",
    "    br = EvalAgentTree(t_prof, br_agent=agent, mode=None, device=None)\n",
    "    br.mode = \"BR\"\n",
    "    return br\n",
    "\n",
    "def bayesian_while_play(bayesian_agent, enemy_agent, args={'lr':1e-2, 'iters':10000}):\n",
    "    \"\"\"\n",
    "    Train bayesian_agent to mimic stationery enemy_agent.\n",
    "    \"\"\"\n",
    "            \n",
    "    env_bldr = bayesian_agent.env_bldr\n",
    "    env_cls = env_bldr.env_cls\n",
    "    env_args = env_bldr.env_args\n",
    "    lut_holder = env_cls.get_lut_holder()\n",
    "    \n",
    "    assert(bayesian_agent.env_bldr.env_cls == enemy_agent.env_bldr.env_cls)\n",
    "    assert(env_args.n_seats == 2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    REFERENCE_AGENT = 0\n",
    "    \n",
    "    _env = env_cls(env_args=env_args, lut_holder=lut_holder, is_evaluating=True)\n",
    "    _eval_agents = [enemy_agent, deepcopy(bayesian_agent)] # play against an new frozen copy of the BR to agent while training\n",
    "    \n",
    "    results = {\n",
    "        \"winnings\": []\n",
    "    }\n",
    "    iters = 0 # number of hands played\n",
    "    evals = 0 # number of teaching moments\n",
    "\n",
    "    while iters < args['iters']:\n",
    "        iters += 1\n",
    "        \n",
    "        if iters % 100 == 0:\n",
    "            print(\"Iters {} | Evals {} | Winnings mBB/Hand {} | \".format(\n",
    "                iters, evals, sum(results[\"winnings\"]) / iters\n",
    "            ))\n",
    "            \n",
    "            # play against an new frozen copy of the BR to agent while training\n",
    "            _eval_agents[1] = best_response(deepcopy(bayesian_agent)) \n",
    "        \n",
    "        for seat_p0 in range(_env.N_SEATS):\n",
    "            seat_p1 = 1 - seat_p0\n",
    "            \n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            # Reset Episode\n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            _, r_for_all, done, info = _env.reset()\n",
    "            for e in _eval_agents:\n",
    "                e.reset(deck_state_dict=_env.cards_state_dict())\n",
    "\n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            # Play Episode\n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "            while not done:\n",
    "                p_id_acting = _env.current_player.seat_id\n",
    "\n",
    "                if p_id_acting == seat_p0:\n",
    "                    evals += 1 #increment counter\n",
    "                    \n",
    "                    # set bayesian agent to position of agent 1, update psuedocount\n",
    "                    bayesian_agent.set_env_wrapper(_eval_agents[REFERENCE_AGENT]._internal_env_wrapper)\n",
    "                    node = bayesian_agent._find_node_by_env(bayesian_agent._internal_env_wrapper._action_history_list)\n",
    "                    range_idx = bayesian_agent._internal_env_wrapper.env.get_range_idx(p_id=p_id_acting) #get opponent hole card\n",
    "                    \n",
    "                    # get true values \n",
    "                    action_int, _ = _eval_agents[REFERENCE_AGENT].get_action(step_env=True, need_probs=False)\n",
    "                    \n",
    "                    # update pseudocount\n",
    "                    node.data[range_idx, action_int] += 1 #node.allowed_actions.index(action_int)\n",
    "                    \n",
    "                    # notify opponent\n",
    "                    _eval_agents[1 - REFERENCE_AGENT].notify_of_action(p_id_acted=p_id_acting,\n",
    "                                                                       action_he_did=action_int)\n",
    "                    \n",
    "                elif p_id_acting == seat_p1:\n",
    "                    action_int, _ = _eval_agents[1 - REFERENCE_AGENT].get_action(step_env=True,\n",
    "                                                                                 need_probs=False)\n",
    "                    _eval_agents[REFERENCE_AGENT].notify_of_action(p_id_acted=p_id_acting,\n",
    "                                                                   action_he_did=action_int)\n",
    "                else:\n",
    "                    raise ValueError(\"Only HU supported!\")\n",
    "\n",
    "                _, r_for_all, done, info = _env.step(action_int)\n",
    "                \n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            # Add Rews\n",
    "            # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "            results[\"winnings\"].append(r_for_all[seat_p0] * _env.REWARD_SCALAR * _env.EV_NORMALIZER)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Time taken\", end_time - start_time)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_file1 = \"/home/leduc/poker_ai_data/eval_agent/SD-CFR_LEDUC_EXAMPLE_200/120/eval_agentAVRG_NET.pkl\"\n",
    "agent_file2 = \"/home/leduc/poker_ai_data/eval_agent/SD-CFR_LEDUC_EXAMPLE_200/20/eval_agentAVRG_NET.pkl\"\n",
    "agent_file3 = \"/home/leduc/poker_ai_data/eval_agent/SD-CFR_LEDUC_EXAMPLE_2/2/eval_agentAVRG_NET.pkl\"\n",
    "\n",
    "nash_agent = EvalAgentDeepCFR.load_from_disk(path_to_eval_agent=agent_file1)\n",
    "\n",
    "def get_random_agent():\n",
    "    random_agent = EvalAgentTree(t_prof, br_agent=nash_agent, mode=None, device=None)\n",
    "    random_agent.tree.fill_uniform_random()\n",
    "    random_agent.mode = \"EVAL\"\n",
    "    return random_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ONLY RUN THIS ONCE, THEN CALL FROM HERE \n",
    "\n",
    "\n",
    "## To exploit\n",
    "strong_agent = EvalAgentDeepCFR.load_from_disk(path_to_eval_agent=agent_file2)\n",
    "weak_agent = EvalAgentDeepCFR.load_from_disk(path_to_eval_agent=agent_file3)\n",
    "random_agent = get_random_agent()\n",
    "\n",
    "exploited_agents = [('strong_agent', strong_agent), ('weak_agent', weak_agent), ('random_agent', random_agent)]\n",
    "\n",
    "## To test with\n",
    "bayesian_agent = EvalAgentTree(t_prof, br_agent=nash_agent, mode=\"BAYESIAN\", device=None)\n",
    "\n",
    "mab_agents = [get_random_agent() for i in range(22)] + [strong_agent, weak_agent, nash_agent]\n",
    "\n",
    "student_agent = EvalAgentDeepRange(t_prof, mode=None, device=None)\n",
    "student_agent.policy[0]._net.load_state_dict(nash_agent.avrg_net_policies[0]._net.state_dict())\n",
    "student_agent.policy[1]._net.load_state_dict(nash_agent.avrg_net_policies[1]._net.state_dict())\n",
    "\n",
    "test_agents = [('student_agent', student_agent), ('bayesian_agent', bayesian_agent), ('mab_agent', mab_agents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iters 100 | Evals 399 | Winnings mBB/Hand -620.0 | \n",
      "Iters 200 | Evals 908 | Winnings mBB/Hand -2470.0 | \n",
      "Iters 300 | Evals 1402 | Winnings mBB/Hand -2850.0 | \n",
      "Iters 400 | Evals 1897 | Winnings mBB/Hand -3527.5 | \n",
      "Iters 500 | Evals 2394 | Winnings mBB/Hand -3802.0 | \n",
      "Iters 600 | Evals 2892 | Winnings mBB/Hand -3928.3333333333335 | \n",
      "Iters 700 | Evals 3393 | Winnings mBB/Hand -4038.5714285714284 | \n",
      "Iters 800 | Evals 3882 | Winnings mBB/Hand -4081.25 | \n",
      "Iters 900 | Evals 4398 | Winnings mBB/Hand -4135.555555555556 | \n",
      "Iters 1000 | Evals 4920 | Winnings mBB/Hand -4167.0 | \n",
      "Iters 1100 | Evals 5427 | Winnings mBB/Hand -4121.818181818182 | \n",
      "Iters 1200 | Evals 5961 | Winnings mBB/Hand -4211.666666666667 | \n",
      "Iters 1300 | Evals 6482 | Winnings mBB/Hand -4164.615384615385 | \n",
      "Iters 1400 | Evals 6989 | Winnings mBB/Hand -4192.857142857143 | \n",
      "Iters 1500 | Evals 7490 | Winnings mBB/Hand -4231.333333333333 | \n",
      "Iters 1600 | Evals 8017 | Winnings mBB/Hand -4305.0 | \n",
      "Iters 1700 | Evals 8542 | Winnings mBB/Hand -4314.117647058823 | \n",
      "Iters 1800 | Evals 9048 | Winnings mBB/Hand -4276.111111111111 | \n",
      "Iters 1900 | Evals 9561 | Winnings mBB/Hand -4243.684210526316 | \n",
      "Iters 2000 | Evals 10080 | Winnings mBB/Hand -4289.0 | \n",
      "Iters 2100 | Evals 10609 | Winnings mBB/Hand -4271.9047619047615 | \n",
      "Iters 2200 | Evals 11121 | Winnings mBB/Hand -4277.272727272727 | \n",
      "Iters 2300 | Evals 11646 | Winnings mBB/Hand -4288.695652173913 | \n",
      "Iters 2400 | Evals 12152 | Winnings mBB/Hand -4287.5 | \n",
      "Iters 2500 | Evals 12670 | Winnings mBB/Hand -4304.8 | \n",
      "Iters 2600 | Evals 13181 | Winnings mBB/Hand -4350.384615384615 | \n",
      "Iters 2700 | Evals 13712 | Winnings mBB/Hand -4322.962962962963 | \n",
      "Iters 2800 | Evals 14224 | Winnings mBB/Hand -4312.857142857143 | \n",
      "Iters 2900 | Evals 14747 | Winnings mBB/Hand -4300.689655172414 | \n",
      "Iters 3000 | Evals 15276 | Winnings mBB/Hand -4299.666666666667 | \n",
      "Iters 3100 | Evals 15786 | Winnings mBB/Hand -4303.548387096775 | \n",
      "Iters 3200 | Evals 16295 | Winnings mBB/Hand -4292.8125 | \n",
      "Iters 3300 | Evals 16823 | Winnings mBB/Hand -4280.30303030303 | \n",
      "Iters 3400 | Evals 17350 | Winnings mBB/Hand -4324.117647058823 | \n",
      "Iters 3500 | Evals 17861 | Winnings mBB/Hand -4324.571428571428 | \n",
      "Iters 3600 | Evals 18368 | Winnings mBB/Hand -4288.055555555556 | \n",
      "Iters 3700 | Evals 18876 | Winnings mBB/Hand -4289.189189189189 | \n",
      "Iters 3800 | Evals 19398 | Winnings mBB/Hand -4326.0526315789475 | \n",
      "Iters 3900 | Evals 19908 | Winnings mBB/Hand -4333.846153846154 | \n",
      "Iters 4000 | Evals 20426 | Winnings mBB/Hand -4308.5 | \n",
      "Iters 4100 | Evals 20946 | Winnings mBB/Hand -4284.634146341464 | \n",
      "Iters 4200 | Evals 21449 | Winnings mBB/Hand -4294.761904761905 | \n",
      "Iters 4300 | Evals 21964 | Winnings mBB/Hand -4297.674418604651 | \n",
      "Iters 4400 | Evals 22489 | Winnings mBB/Hand -4301.818181818182 | \n",
      "Iters 4500 | Evals 22994 | Winnings mBB/Hand -4317.777777777777 | \n",
      "Iters 4600 | Evals 23509 | Winnings mBB/Hand -4312.173913043478 | \n",
      "Iters 4700 | Evals 24027 | Winnings mBB/Hand -4307.659574468085 | \n",
      "Iters 4800 | Evals 24531 | Winnings mBB/Hand -4298.333333333333 | \n",
      "Iters 4900 | Evals 25040 | Winnings mBB/Hand -4313.469387755102 | \n",
      "Iters 5000 | Evals 25554 | Winnings mBB/Hand -4290.0 | \n",
      "Time taken 37.23277497291565\n",
      "Iters 100 | Evals 404 | ActionLoss 1.0629889965057373 | Winnings mBB/Hand -1150.0 | \n",
      "Iters 200 | Evals 806 | ActionLoss 1.0470763444900513 | Winnings mBB/Hand -1670.0 | \n",
      "Iters 300 | Evals 1279 | ActionLoss 1.0390459299087524 | Winnings mBB/Hand -2276.6666666666665 | \n",
      "Iters 400 | Evals 1757 | ActionLoss 1.0213693380355835 | Winnings mBB/Hand -2692.5 | \n",
      "Iters 500 | Evals 2249 | ActionLoss 1.0131940841674805 | Winnings mBB/Hand -2926.0 | \n",
      "Iters 600 | Evals 2734 | ActionLoss 1.010098934173584 | Winnings mBB/Hand -3021.6666666666665 | \n",
      "Iters 700 | Evals 3258 | ActionLoss 1.0072299242019653 | Winnings mBB/Hand -2890.0 | \n",
      "Iters 800 | Evals 3773 | ActionLoss 1.0045435428619385 | Winnings mBB/Hand -3195.0 | \n",
      "Iters 900 | Evals 4281 | ActionLoss 1.0014172792434692 | Winnings mBB/Hand -3348.8888888888887 | \n",
      "Iters 1000 | Evals 4778 | ActionLoss 0.9994047284126282 | Winnings mBB/Hand -3351.0 | \n",
      "Iters 1100 | Evals 5291 | ActionLoss 0.9973264336585999 | Winnings mBB/Hand -3476.3636363636365 | \n",
      "Iters 1200 | Evals 5775 | ActionLoss 0.9955134987831116 | Winnings mBB/Hand -3507.5 | \n",
      "Iters 1300 | Evals 6243 | ActionLoss 0.9943718314170837 | Winnings mBB/Hand -3544.6153846153848 | \n",
      "Iters 1400 | Evals 6729 | ActionLoss 0.993191659450531 | Winnings mBB/Hand -3622.1428571428573 | \n",
      "Iters 1500 | Evals 7202 | ActionLoss 0.9914904236793518 | Winnings mBB/Hand -3706.0 | \n",
      "Iters 1600 | Evals 7641 | ActionLoss 0.9909283518791199 | Winnings mBB/Hand -3679.375 | \n",
      "Iters 1700 | Evals 8113 | ActionLoss 0.9899003505706787 | Winnings mBB/Hand -3704.1176470588234 | \n",
      "Iters 1800 | Evals 8589 | ActionLoss 0.9881283044815063 | Winnings mBB/Hand -3748.3333333333335 | \n",
      "Iters 1900 | Evals 9074 | ActionLoss 0.9865604639053345 | Winnings mBB/Hand -3724.2105263157896 | \n",
      "Iters 2000 | Evals 9553 | ActionLoss 0.9849544167518616 | Winnings mBB/Hand -3718.0 | \n",
      "Iters 2100 | Evals 10042 | ActionLoss 0.9840051531791687 | Winnings mBB/Hand -3711.4285714285716 | \n",
      "Iters 2200 | Evals 10533 | ActionLoss 0.9831417202949524 | Winnings mBB/Hand -3690.909090909091 | \n",
      "Iters 2300 | Evals 11028 | ActionLoss 0.9823126792907715 | Winnings mBB/Hand -3704.782608695652 | \n",
      "Iters 2400 | Evals 11522 | ActionLoss 0.9809632301330566 | Winnings mBB/Hand -3714.5833333333335 | \n",
      "Iters 2500 | Evals 12036 | ActionLoss 0.9803524017333984 | Winnings mBB/Hand -3720.0 | \n",
      "Iters 2600 | Evals 12540 | ActionLoss 0.9796596765518188 | Winnings mBB/Hand -3695.0 | \n",
      "Iters 2700 | Evals 13047 | ActionLoss 0.9787512421607971 | Winnings mBB/Hand -3720.3703703703704 | \n",
      "Iters 2800 | Evals 13562 | ActionLoss 0.9782301783561707 | Winnings mBB/Hand -3750.3571428571427 | \n",
      "Iters 2900 | Evals 14068 | ActionLoss 0.977952778339386 | Winnings mBB/Hand -3787.2413793103447 | \n",
      "Iters 3000 | Evals 14549 | ActionLoss 0.9781456589698792 | Winnings mBB/Hand -3778.0 | \n",
      "Iters 3100 | Evals 15062 | ActionLoss 0.977875828742981 | Winnings mBB/Hand -3855.1612903225805 | \n",
      "Iters 3200 | Evals 15560 | ActionLoss 0.9774466753005981 | Winnings mBB/Hand -3846.5625 | \n",
      "Iters 3300 | Evals 16045 | ActionLoss 0.9776219129562378 | Winnings mBB/Hand -3853.6363636363635 | \n",
      "Iters 3400 | Evals 16528 | ActionLoss 0.977419376373291 | Winnings mBB/Hand -3838.529411764706 | \n",
      "Iters 3500 | Evals 16999 | ActionLoss 0.9773429036140442 | Winnings mBB/Hand -3864.5714285714284 | \n",
      "Iters 3600 | Evals 17493 | ActionLoss 0.9770326614379883 | Winnings mBB/Hand -3867.222222222222 | \n",
      "Iters 3700 | Evals 18007 | ActionLoss 0.9764559864997864 | Winnings mBB/Hand -3885.135135135135 | \n",
      "Iters 3800 | Evals 18518 | ActionLoss 0.9755472540855408 | Winnings mBB/Hand -3908.9473684210525 | \n",
      "Iters 3900 | Evals 19041 | ActionLoss 0.9750910401344299 | Winnings mBB/Hand -3959.74358974359 | \n",
      "Iters 4000 | Evals 19559 | ActionLoss 0.9741934537887573 | Winnings mBB/Hand -3951.75 | \n",
      "Iters 4100 | Evals 20109 | ActionLoss 0.9736775159835815 | Winnings mBB/Hand -3991.951219512195 | \n",
      "Iters 4200 | Evals 20655 | ActionLoss 0.9730817675590515 | Winnings mBB/Hand -3990.0 | \n",
      "Iters 4300 | Evals 21186 | ActionLoss 0.9725664854049683 | Winnings mBB/Hand -3997.906976744186 | \n",
      "Iters 4400 | Evals 21718 | ActionLoss 0.9721750020980835 | Winnings mBB/Hand -4014.090909090909 | \n",
      "Iters 4500 | Evals 22255 | ActionLoss 0.9715628623962402 | Winnings mBB/Hand -4038.0 | \n",
      "Iters 4600 | Evals 22807 | ActionLoss 0.9708301424980164 | Winnings mBB/Hand -4016.9565217391305 | \n",
      "Iters 4700 | Evals 23337 | ActionLoss 0.9704942107200623 | Winnings mBB/Hand -4011.063829787234 | \n",
      "Iters 4800 | Evals 23858 | ActionLoss 0.9702563881874084 | Winnings mBB/Hand -4024.7916666666665 | \n",
      "Iters 4900 | Evals 24326 | ActionLoss 0.9702149033546448 | Winnings mBB/Hand -4007.3469387755104 | \n",
      "Iters 5000 | Evals 24811 | ActionLoss 0.970012366771698 | Winnings mBB/Hand -3999.0 | \n",
      "Time taken 90.48256492614746\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.02\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -750.0 +/- 1321.1838478338602\n",
      "Player  AVRG_NET: 750.0 +/- 1321.1838478338602\n",
      "UCB List:  [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 0 -750.0 1 -750.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: -400.0 +/- 1705.312679047364\n",
      "Player  AVRG_NET: 400.0 +/- 1705.312679047364\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 500.0 +/- 1897.7615968060495\n",
      "Player  AVRG_NET: -500.0 +/- 1897.7615968060495\n",
      "UCB List:  [-749.4112949887423, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 1 500.0 1 500.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: -850.0 +/- 1394.736589664169\n",
      "Player  AVRG_NET: 850.0 +/- 1394.736589664169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 1950.0 +/- 1957.4257164509825\n",
      "Player  AVRG_NET: -1950.0 +/- 1957.4257164509825\n",
      "UCB List:  [-749.2588480963162, 500.7411519036838, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 2 1950.0 1 1950.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 1200.0 +/- 2044.4219631848957\n",
      "Player  AVRG_NET: -1200.0 +/- 2044.4219631848957\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 700.0 +/- 1726.0244355654268\n",
      "Player  AVRG_NET: -700.0 +/- 1726.0244355654268\n",
      "UCB List:  [-749.1674453888423, 500.8325546111577, 1950.8325546111578, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 3 700.0 1 700.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 900.0 +/- 1713.7395195865854\n",
      "Player  AVRG_NET: -900.0 +/- 1713.7395195865854\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 900.0 +/- 2747.1480897979327\n",
      "Player  AVRG_NET: -900.0 +/- 2747.1480897979327\n",
      "UCB List:  [-749.1029387110029, 500.89706128899707, 1950.897061288997, 700.8970612889971, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 4 900.0 1 900.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 300.0 +/- 2097.7493675266924\n",
      "Player  AVRG_NET: -300.0 +/- 2097.7493675266924\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -100.0 +/- 1517.5767615074692\n",
      "Player  AVRG_NET: 100.0 +/- 1517.5767615074692\n",
      "UCB List:  [-749.0534907635875, 500.9465092364124, 1950.9465092364123, 700.9465092364125, 900.9465092364125, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 5 -100.0 1 -100.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 1600.0 +/- 2034.0607884582087\n",
      "Player  AVRG_NET: -1600.0 +/- 2034.0607884582087\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 250.0 +/- 1752.3922845430325\n",
      "Player  AVRG_NET: -250.0 +/- 1752.3922845430325\n",
      "UCB List:  [-749.0136151488756, 500.9863848511244, 1950.9863848511243, 700.9863848511244, 900.9863848511244, -99.01361514887563, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 6 250.0 1 250.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 1650.0 +/- 2084.7756967539185\n",
      "Player  AVRG_NET: -1650.0 +/- 2084.7756967539185\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -950.0 +/- 1902.6895587121185\n",
      "Player  AVRG_NET: 950.0 +/- 1902.6895587121185\n",
      "UCB List:  [-748.9803330098312, 501.0196669901688, 1951.0196669901688, 701.0196669901688, 901.0196669901688, -98.98033300983118, 251.01966699016882, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 7 -950.0 1 -950.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 400.0 +/- 1835.5061669856527\n",
      "Player  AVRG_NET: -400.0 +/- 1835.5061669856527\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 1600.0 +/- 2713.7330498559027\n",
      "Player  AVRG_NET: -1600.0 +/- 2713.7330498559027\n",
      "UCB List:  [-748.9518529260318, 501.0481470739682, 1951.0481470739683, 701.0481470739682, 901.0481470739682, -98.95185292603179, 251.0481470739682, -948.9518529260318, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 8 1600.0 1 1600.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 650.0 +/- 1359.8712805785992\n",
      "Player  AVRG_NET: -650.0 +/- 1359.8712805785992\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 950.0 +/- 1962.326072525634\n",
      "Player  AVRG_NET: -950.0 +/- 1962.326072525634\n",
      "UCB List:  [-748.9270169868553, 501.07298301314466, 1951.0729830131447, 701.0729830131447, 901.0729830131447, -98.92701698685532, 251.07298301314466, -948.9270169868553, 1601.0729830131447, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 9 950.0 1 950.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 1050.0 +/- 2624.0402055894906\n",
      "Player  AVRG_NET: -1050.0 +/- 2624.0402055894906\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -1550.0 +/- 2706.9118415114544\n",
      "Player  AVRG_NET: 1550.0 +/- 2706.9118415114544\n",
      "UCB List:  [-748.9050353264149, 501.094964673585, 1951.094964673585, 701.0949646735851, 901.0949646735851, -98.90503532641496, 251.09496467358503, -948.9050353264149, 1601.094964673585, 951.0949646735851, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 10 -1550.0 1 -1550.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 1150.0 +/- 2130.345006472616\n",
      "Player  AVRG_NET: -1150.0 +/- 2130.345006472616\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 100.0 +/- 2007.924058069215\n",
      "Player  AVRG_NET: -100.0 +/- 2007.924058069215\n",
      "UCB List:  [-748.8853460963627, 501.11465390363736, 1951.1146539036374, 701.1146539036373, 901.1146539036373, -98.88534609636264, 251.11465390363736, -948.8853460963627, 1601.1146539036374, 951.1146539036373, -1548.8853460963626, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 11 100.0 1 100.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 700.0 +/- 1818.1572929312397\n",
      "Player  AVRG_NET: -700.0 +/- 1818.1572929312397\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 2050.0 +/- 2430.222231191319\n",
      "Player  AVRG_NET: -2050.0 +/- 2430.222231191319\n",
      "UCB List:  [-748.8675360143781, 501.13246398562194, 1951.132463985622, 701.1324639856219, 901.1324639856219, -98.86753601437805, 251.13246398562197, -948.8675360143781, 1601.132463985622, 951.1324639856219, -1548.867536014378, 101.13246398562195, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 12 2050.0 1 2050.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 600.0 +/- 1952.1442287038142\n",
      "Player  AVRG_NET: -600.0 +/- 1952.1442287038142\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -600.0 +/- 2361.7796711543047\n",
      "Player  AVRG_NET: 600.0 +/- 2361.7796711543047\n",
      "UCB List:  [-748.8512926113202, 501.14870738867984, 1951.14870738868, 701.1487073886798, 901.1487073886798, -98.85129261132018, 251.14870738867984, -948.8512926113202, 1601.14870738868, 951.1487073886798, -1548.85129261132, 101.14870738867982, 2051.1487073886797, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 13 -600.0 1 -600.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 2650.0 +/- 1876.258580120031\n",
      "Player  AVRG_NET: -2650.0 +/- 1876.258580120031\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -300.0 +/- 1737.1173788233714\n",
      "Player  AVRG_NET: 300.0 +/- 1737.1173788233714\n",
      "UCB List:  [-748.8363741578363, 501.16362584216364, 1951.1636258421636, 701.1636258421637, 901.1636258421637, -98.83637415783633, 251.16362584216367, -948.8363741578363, 1601.1636258421636, 951.1636258421637, -1548.8363741578364, 101.16362584216367, 2051.1636258421636, -598.8363741578363, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 14 -300.0 1 -300.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 750.0 +/- 1919.7745723778667\n",
      "Player  AVRG_NET: -750.0 +/- 1919.7745723778667\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -1500.0 +/- 2228.2879283577004\n",
      "Player  AVRG_NET: 1500.0 +/- 2228.2879283577004\n",
      "UCB List:  [-748.8225899774845, 501.17741002251546, 1951.1774100225155, 701.1774100225155, 901.1774100225155, -98.82258997748453, 251.1774100225155, -948.8225899774845, 1601.1774100225155, 951.1774100225155, -1548.8225899774845, 101.17741002251547, 2051.1774100225157, -598.8225899774845, -298.82258997748454, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 15 -1500.0 1 -1500.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 500.0 +/- 1932.8620904554014\n",
      "Player  AVRG_NET: -500.0 +/- 1932.8620904554014\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 1400.0 +/- 1892.1869308492535\n",
      "Player  AVRG_NET: -1400.0 +/- 1892.1869308492535\n",
      "UCB List:  [-748.8097871316323, 501.1902128683677, 1951.1902128683678, 701.1902128683677, 901.1902128683677, -98.80978713163228, 251.19021286836772, -948.8097871316323, 1601.1902128683678, 951.1902128683677, -1548.8097871316322, 101.19021286836772, 2051.190212868368, -598.8097871316323, -298.8097871316323, -1498.8097871316322, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 16 1400.0 1 1400.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: -50.0 +/- 2275.0990724928006\n",
      "Player  AVRG_NET: 50.0 +/- 2275.0990724928006\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -150.0 +/- 1145.1750586790872\n",
      "Player  AVRG_NET: 150.0 +/- 1145.1750586790872\n",
      "UCB List:  [-748.7978411590193, 501.2021588409807, 1951.2021588409807, 701.2021588409807, 901.2021588409807, -98.79784115901928, 251.2021588409807, -948.7978411590193, 1601.2021588409807, 951.2021588409807, -1548.7978411590193, 101.20215884098072, 2051.2021588409807, -598.7978411590193, -298.7978411590193, -1498.7978411590193, 1401.2021588409807, inf, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 17 -150.0 1 -150.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 750.0 +/- 2031.580329605801\n",
      "Player  AVRG_NET: -750.0 +/- 2031.580329605801\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: 650.0 +/- 1961.3470285044307\n",
      "Player  AVRG_NET: -650.0 +/- 1961.3470285044307\n",
      "UCB List:  [-748.7866494778576, 501.2133505221424, 1951.2133505221425, 701.2133505221424, 901.2133505221424, -98.78664947785761, 251.2133505221424, -948.7866494778576, 1601.2133505221425, 951.2133505221424, -1548.7866494778575, 101.21335052214239, 2051.2133505221423, -598.7866494778576, -298.7866494778576, -1498.7866494778575, 1401.2133505221425, -148.7866494778576, inf, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 18 650.0 1 650.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 2250.0 +/- 1696.7023346287585\n",
      "Player  AVRG_NET: -2250.0 +/- 1696.7023346287585\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -400.0 +/- 1520.7377362041232\n",
      "Player  AVRG_NET: 400.0 +/- 1520.7377362041232\n",
      "UCB List:  [-748.7761265846596, 501.2238734153404, 1951.2238734153404, 701.2238734153404, 901.2238734153404, -98.7761265846596, 251.22387341534042, -948.7761265846596, 1601.2238734153404, 951.2238734153404, -1548.7761265846596, 101.2238734153404, 2051.22387341534, -598.7761265846596, -298.7761265846596, -1498.7761265846596, 1401.2238734153404, -148.77612658465958, 651.2238734153404, inf, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 19 -400.0 1 -400.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 900.0 +/- 1969.2880920101807\n",
      "Player  AVRG_NET: -900.0 +/- 1969.2880920101807\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -1550.0 +/- 1155.195012489532\n",
      "Player  AVRG_NET: 1550.0 +/- 1155.195012489532\n",
      "UCB List:  [-748.7662004948689, 501.23379950513106, 1951.2337995051312, 701.2337995051311, 901.2337995051311, -98.76620049486891, 251.2337995051311, -948.7662004948689, 1601.2337995051312, 951.2337995051311, -1548.7662004948688, 101.23379950513109, 2051.233799505131, -598.7662004948689, -298.76620049486894, -1498.7662004948688, 1401.2337995051312, -148.7662004948689, 651.2337995051311, -398.76620049486894, inf, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 20 -1550.0 1 -1550.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 1700.0 +/- 2302.895576745937\n",
      "Player  AVRG_NET: -1700.0 +/- 2302.895576745937\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  COPYCAT: -350.0 +/- 1860.839118283141\n",
      "Player  AVRG_NET: 350.0 +/- 1860.839118283141\n",
      "UCB List:  [-748.7568100600957, 501.24318993990425, 1951.2431899399044, 701.2431899399043, 901.2431899399043, -98.75681006009575, 251.24318993990425, -948.7568100600957, 1601.2431899399044, 951.2431899399043, -1548.7568100600956, 101.24318993990425, 2051.2431899399044, -598.7568100600957, -298.75681006009575, -1498.7568100600956, 1401.2431899399044, -148.75681006009575, 651.2431899399043, -398.75681006009575, -1548.7568100600956, inf, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 21 -350.0 1 -350.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: -650.0 +/- 1394.736589664169\n",
      "Player  AVRG_NET: 650.0 +/- 1394.736589664169\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: 700.0 +/- 1308.2174530166535\n",
      "Player  AVRG_NET: -700.0 +/- 1308.2174530166535\n",
      "UCB List:  [-748.7479029159189, 501.2520970840812, 1951.2520970840812, 701.2520970840811, 901.2520970840811, -98.74790291591883, 251.25209708408119, -948.7479029159189, 1601.2520970840812, 951.2520970840811, -1548.7479029159188, 101.25209708408117, 2051.252097084081, -598.7479029159189, -298.7479029159188, -1498.7479029159188, 1401.2520970840812, -148.74790291591881, 651.2520970840811, -398.7479029159188, -1548.7479029159188, -348.7479029159188, inf, inf, inf]\n",
      "best agent, reward, arm_times, avg reward 22 700.0 1 700.0\n",
      "\n",
      "Played 20 hands of poker.\n",
      "Player  AVRG_NET: -150.0 +/- 1218.3176720139566\n",
      "Player  AVRG_NET: 150.0 +/- 1218.3176720139566\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-83dae913ac56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstudent_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_while_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menemy_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iters'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbandit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmab_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menemy_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbandit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opp-modelling/ucb.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_episodes)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mbest_agent_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mucb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2HEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_agent_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2h_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UCB List: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mucb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opp-modelling/H2HEvaluator.py\u001b[0m in \u001b[0;36mh2h_eval\u001b[0;34m(self, n_games)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmatchup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgentTournament\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_agent_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_agent_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# matchup = DebugAgentTournament(env_cls, env_args, eval_agent_1, eval_agent_2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_conf95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_conf95\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatchup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_games_per_seat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PokerRL/PokerRL/game/AgentTournament.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_games_per_seat)\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0maction_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_agents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mREFERENCE_AGENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                         self._eval_agents[1 - REFERENCE_AGENT].notify_of_action(p_id_acted=p_id_acting,\n\u001b[0;32m---> 44\u001b[0;31m                                                                                 action_he_did=action_int)\n\u001b[0m\u001b[1;32m     45\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0mp_id_acting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mseat_p1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         action_int, _ = self._eval_agents[1 - REFERENCE_AGENT].get_action(step_env=True,\n",
      "\u001b[0;32m~/PokerRL/PokerRL/rl/base_cls/EvalAgentBase.py\u001b[0m in \u001b[0;36mnotify_of_action\u001b[0;34m(self, p_id_acted, action_he_did)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# __________________________________________________ Notifications _________________________________________________\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnotify_of_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_id_acted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_he_did\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_env_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_player\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseat_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mp_id_acted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_env_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_he_did\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enemy_agent = weak_agent\n",
    "iters = 5000\n",
    "\n",
    "bayesian_results = bayesian_while_play(bayesian_agent, enemy_agent, args={'lr':1e-2, 'iters':iters})\n",
    "student_results = train_while_play(student_agent, enemy_agent, args={'lr':2e-2, 'iters':iters})\n",
    "bandit = MAB(mab_agents, enemy_agent, gamma = 0.5, n_hands = 10)\n",
    "bandit.run(n_episodes=int(iters/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Exploiting Weak Agent')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "sns.despine()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xlabel('Hands Played')\n",
    "plt.ylabel('Average EV')\n",
    "plt.plot(list(range(0,iters,25)), [0] + [-sum(bayesian_results['winnings'][:i])/i for i in range(25,iters,25)], label='bayesian')\n",
    "plt.plot(list(range(0,iters,25)), [0] + [-sum(student_results['winnings'][:i])/i for i in range(25,iters,25)], label='student')\n",
    "plt.plot(list(range(0,iters+10,210)), bandit.reward_list, label='multi-arm bandit')\n",
    "plt.plot(list(range(0,iters+10,210)), [0] + bandit.nash, label='nash')\n",
    "plt.axhline(y=2180, label='oracle', color='red')\n",
    "plt.legend()\n",
    "plt.title(\"Exploiting Weak Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weak agent vs Oracle\n",
      "\n",
      "Played 10000 hands of poker.\n",
      "Player  AVRG_NET: -2179.0 +/- 106.80105078125\n",
      "Player  BESTRESPONSE: 2179.0 +/- 106.80105078125\n",
      "\n",
      "Weak agent vs Bayesian\n",
      "\n",
      "Played 10000 hands of poker.\n",
      "Player  AVRG_NET: -2225.0 +/- 105.12650449218751\n",
      "Player  BESTRESPONSE: 2225.0 +/- 105.12650449218751\n",
      "\n",
      "Weak agent vs Nash\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-8ba7fad974a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nWeak agent vs Nash\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mH2HEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menemy_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnash_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2h_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nWeak agent vs Student\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opp-modelling/H2HEvaluator.py\u001b[0m in \u001b[0;36mh2h_eval\u001b[0;34m(self, n_games)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmatchup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgentTournament\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_agent_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_agent_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# matchup = DebugAgentTournament(env_cls, env_args, eval_agent_1, eval_agent_2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_conf95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_conf95\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatchup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_games_per_seat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PokerRL/PokerRL/game/AgentTournament.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_games_per_seat)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp_id_acting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mseat_p0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                         \u001b[0maction_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_agents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mREFERENCE_AGENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                         self._eval_agents[1 - REFERENCE_AGENT].notify_of_action(p_id_acted=p_id_acting,\n\u001b[1;32m     44\u001b[0m                                                                                 action_he_did=action_int)\n",
      "\u001b[0;32m~/Deep-CFR/DeepCFR/EvalAgentDeepCFR.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, step_env, need_probs)\u001b[0m\n\u001b[1;32m    259\u001b[0m                     \u001b[0mpub_obses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_env_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                     \u001b[0mrange_idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                     \u001b[0mlegal_actions_lists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_env_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legal_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                 )[0]\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deep-CFR/DeepCFR/workers/la/AvrgWrapper.py\u001b[0m in \u001b[0;36mget_a_probs\u001b[0;34m(self, pub_obses, range_idxs, legal_actions_lists)\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                               device=self.device)\n\u001b[1;32m     33\u001b[0m             \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_a_probs2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpub_obses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpub_obses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_action_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_a_probs2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpub_obses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_action_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deep-CFR/DeepCFR/workers/la/AvrgWrapper.py\u001b[0m in \u001b[0;36mget_a_probs2\u001b[0;34m(self, pub_obses, range_idxs, legal_action_masks)\u001b[0m\n\u001b[1;32m     38\u001b[0m             pred = self._net(pub_obses=pub_obses,\n\u001b[1;32m     39\u001b[0m                              \u001b[0mrange_idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                              legal_action_masks=legal_action_masks)\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leduc3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PokerRL/PokerRL/rl/neural/AvrgStrategyNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pub_obses, range_idxs, legal_action_masks)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \"\"\"\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpub_obses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpub_obses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/leduc3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PokerRL/PokerRL/rl/neural/MainPokerModuleFLAT.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pub_obses, range_idxs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Normalize last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Absolute Best Response\n",
    "\n",
    "from H2HEvaluator import H2HEval\n",
    "\n",
    "agent_file1 = \"/home/leduc/poker_ai_data/eval_agent/SD-CFR_LEDUC_EXAMPLE_200/120/eval_agentAVRG_NET.pkl\"\n",
    "\n",
    "nash_agent = EvalAgentDeepCFR.load_from_disk(path_to_eval_agent=agent_file1)\n",
    "\n",
    "def best_response(agent):\n",
    "    \"\"\"\n",
    "    Returns strategy that is best response to agent strategy\n",
    "    \"\"\"\n",
    "    br = EvalAgentTree(t_prof, br_agent=agent, mode=None, device=None)\n",
    "    br.mode = \"BR\"\n",
    "    return br\n",
    "\n",
    "n_games = 5000\n",
    "\n",
    "print(\"\\nWeak agent vs Oracle\")\n",
    "H2HEval(enemy_agent, best_response(enemy_agent)).h2h_eval(n_games=n_games)\n",
    "\n",
    "print(\"\\nWeak agent vs Bayesian\")\n",
    "H2HEval(enemy_agent, best_response(bayesian_agent)).h2h_eval(n_games=n_games)\n",
    "\n",
    "print(\"\\nWeak agent vs Nash\")\n",
    "H2HEval(enemy_agent, nash_agent).h2h_eval(n_games=n_games)\n",
    "\n",
    "print(\"\\nWeak agent vs Student\")\n",
    "H2HEval(enemy_agent, best_response(student_agent)).h2h_eval(n_games=n_games)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2150.0,\n",
       " 2125.0,\n",
       " 2050.0,\n",
       " 1425.0,\n",
       " 1590.0,\n",
       " 1675.0,\n",
       " 1485.7142857142858,\n",
       " 1431.25,\n",
       " 1427.7777777777778,\n",
       " 1295.0,\n",
       " 1031.8181818181818,\n",
       " 1058.3333333333333,\n",
       " 1011.5384615384615,\n",
       " 971.4285714285714,\n",
       " 863.3333333333334,\n",
       " 731.25,\n",
       " 741.1764705882352,\n",
       " 755.5555555555555,\n",
       " 721.0526315789474,\n",
       " 717.5,\n",
       " 654.7619047619048,\n",
       " 702.2727272727273,\n",
       " 693.4782608695652,\n",
       " 679.1666666666666,\n",
       " 712.0,\n",
       " 678.8461538461538,\n",
       " 688.8888888888889,\n",
       " 703.5714285714286,\n",
       " 675.8620689655172,\n",
       " 720.0,\n",
       " 743.5483870967741,\n",
       " 745.3125,\n",
       " 684.8484848484849,\n",
       " 717.6470588235294,\n",
       " 728.5714285714286,\n",
       " 726.3888888888889,\n",
       " 717.5675675675676,\n",
       " 727.6315789473684,\n",
       " 719.2307692307693,\n",
       " 788.75,\n",
       " 787.8048780487804,\n",
       " 795.2380952380952,\n",
       " 812.7906976744187,\n",
       " 826.1363636363636,\n",
       " 857.7777777777778,\n",
       " 866.304347826087,\n",
       " 854.2553191489362,\n",
       " 867.7083333333334,\n",
       " 875.5102040816327,\n",
       " 903.0,\n",
       " 905.8823529411765,\n",
       " 881.7307692307693,\n",
       " 883.0188679245283,\n",
       " 885.1851851851852,\n",
       " 879.0909090909091,\n",
       " 889.2857142857143,\n",
       " 887.719298245614,\n",
       " 875.0,\n",
       " 900.0,\n",
       " 905.8333333333334,\n",
       " 889.344262295082,\n",
       " 883.8709677419355,\n",
       " 863.4920634920635,\n",
       " 839.0625,\n",
       " 845.3846153846154,\n",
       " 847.7272727272727,\n",
       " 840.2985074626865,\n",
       " 847.0588235294117,\n",
       " 874.6376811594203,\n",
       " 875.7142857142857,\n",
       " 881.6901408450705,\n",
       " 874.3055555555555,\n",
       " 886.3013698630137,\n",
       " 885.8108108108108,\n",
       " 880.6666666666666,\n",
       " 867.7631578947369,\n",
       " 857.1428571428571,\n",
       " 862.8205128205128,\n",
       " 863.2911392405064,\n",
       " 870.625,\n",
       " 847.5308641975308,\n",
       " 841.4634146341464,\n",
       " 847.5903614457832,\n",
       " 825.5952380952381,\n",
       " 838.2352941176471,\n",
       " 835.4651162790698,\n",
       " 832.7586206896551,\n",
       " 827.2727272727273,\n",
       " 832.0224719101124,\n",
       " 821.1111111111111,\n",
       " 823.6263736263736,\n",
       " 826.6304347826087,\n",
       " 803.763440860215,\n",
       " 793.0851063829788,\n",
       " 780.0,\n",
       " 777.6041666666666,\n",
       " 776.8041237113403,\n",
       " 790.8163265306123,\n",
       " 788.8888888888889,\n",
       " 785.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit.nash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
